<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>LitePath Demo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <meta name="description" content="LitePath - Client-side foundation model for whole slide image analysis" />
    <meta name="theme-color" content="#00bcd4" />

    <!-- PWA Meta Tags -->
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="apple-mobile-web-app-title" content="LitePath" />

    <!-- PWA Manifest -->
    <link rel="manifest" href="/showcase/LitePath/manifest.json" />

    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/showcase/LitePath/icons/icon-192.png" />

    <!-- CSS Dependencies -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" rel="stylesheet" />
    <link href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" rel="stylesheet" />
    <link rel="shortcut icon" type="image/x-icon" href="/static/img/logo/favicon.ico" />

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>

<body>
    <!-- Navbar -->
    <nav class="navbar navbar-expand-lg navbar-dark" style="background-color: #052049;">
        <div class="container-fluid">
            <a href="http://www.hkust.edu.hk">
                <img class="inline-block navb-icon" src="/static/img/logo/hkust_logo_white.png" alt="HKUST Logo" style="height: 30px;" />
            </a>
            &nbsp;&nbsp;&nbsp;&nbsp;
            <a class="navbar-brand" href="/">HKUST SMART Lab</a>
            <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbarContent">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="navbar-collapse collapse" id="navbarContent">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                </ul>
            </div>
        </div>
    </nav>

<!-- Custom Styles for LitePath -->
<style>
    :root {
        --lite-primary: #00bcd4;
        /* Cyan */
        --lite-primary-dark: #008ba3;
        --lite-secondary: #0f172a;
        /* Slate 900 */
        --lite-surface: #ffffff;
        --lite-bg: #f1f5f9;
        /* Slate 100 */
        --lite-border: #e2e8f0;
        --lite-text: #334155;
        --lite-text-muted: #64748b;
    }

    body {
        background-color: var(--lite-bg);
        font-family: 'Inter', system-ui, -apple-system, sans-serif;
        color: var(--lite-text);
        overflow-x: hidden;
    }

    /* Layout Structure */
    .lite-wrapper {
        display: flex;
        flex-direction: column;
        height: calc(100vh - 76px);
        /* Adjust for navbar height approx */
        min-height: 800px;
    }

    .lite-main-row {
        flex: 1;
        display: flex;
        overflow: hidden;
    }

    /* Sidebar Controls */
    .lite-sidebar {
        width: 360px;
        background: var(--lite-surface);
        border-right: 1px solid var(--lite-border);
        display: flex;
        flex-direction: column;
        z-index: 20;
        box-shadow: 4px 0 24px rgba(0, 0, 0, 0.04);
        flex-shrink: 0;
    }

    .sidebar-header {
        padding: 24px;
        border-bottom: 1px solid var(--lite-border);
    }

    .lite-brand {
        font-size: 1.5rem;
        font-weight: 300;
        letter-spacing: -0.5px;
        color: var(--lite-secondary);
        display: flex;
        align-items: center;
        margin-bottom: 8px;
    }

    .lite-brand strong {
        font-weight: 700;
        color: var(--lite-primary);
    }

    .lite-tagline {
        font-size: 0.75rem;
        text-transform: uppercase;
        letter-spacing: 1px;
        color: var(--lite-text-muted);
        font-weight: 500;
    }

    .sidebar-content {
        flex: 1;
        padding: 24px;
        overflow-y: auto;
    }

    .sidebar-footer {
        padding: 20px 24px;
        border-top: 1px solid var(--lite-border);
        background: #f8fafc;
        font-size: 0.75rem;
        color: var(--lite-text-muted);
        text-align: center;
    }

    /* Control Cards (Minimalist) */
    .control-group {
        margin-bottom: 32px;
    }

    .group-label {
        font-size: 0.7rem;
        text-transform: uppercase;
        letter-spacing: 1.2px;
        font-weight: 700;
        color: #94a3b8;
        margin-bottom: 12px;
        display: flex;
        align-items: center;
    }

    .group-label::after {
        content: '';
        flex: 1;
        height: 1px;
        background: #e2e8f0;
        margin-left: 10px;
    }

    /* File Input Styling */
    .drop-zone {
        border: 2px dashed #cbd5e1;
        border-radius: 12px;
        padding: 30px 20px;
        text-align: center;
        cursor: pointer;
        transition: all 0.2s ease;
        background: #f8fafc;
        position: relative;
    }

    .drop-zone:hover,
    .drop-zone.dragover {
        border-color: var(--lite-primary);
        background: #ecfeff;
        /* Cyan 50 */
    }

    .drop-zone i {
        font-size: 2rem;
        color: var(--lite-text-muted);
        margin-bottom: 10px;
        display: block;
    }

    .drop-text {
        font-size: 0.9rem;
        font-weight: 500;
        color: var(--lite-text);
    }

    .drop-sub {
        font-size: 0.75rem;
        color: var(--lite-text-muted);
        margin-top: 4px;
    }

    .file-input-hidden {
        position: absolute;
        width: 100%;
        height: 100%;
        top: 0;
        left: 0;
        opacity: 0;
        cursor: pointer;
    }

    /* Buttons */
    .btn-tech {
        background: var(--lite-secondary);
        color: white;
        border: none;
        width: 100%;
        padding: 14px;
        border-radius: 8px;
        font-weight: 600;
        letter-spacing: 0.5px;
        display: flex;
        align-items: center;
        justify-content: center;
        gap: 10px;
        transition: all 0.2s;
        box-shadow: 0 4px 12px rgba(15, 23, 42, 0.15);
    }

    .btn-tech:hover:not(:disabled) {
        background: #1e293b;
        transform: translateY(-1px);
        box-shadow: 0 6px 16px rgba(15, 23, 42, 0.2);
        color: white;
        /* Ensure text stays white */
        text-decoration: none;
    }

    .btn-tech:disabled {
        background: #cbd5e1;
        color: #94a3b8;
        cursor: not-allowed;
        box-shadow: none;
    }

    .btn-tech i {
        color: var(--lite-primary);
    }

    /* Status Indicators */
    .status-row {
        display: flex;
        align-items: center;
        justify-content: space-between;
        padding: 12px;
        background: white;
        border: 1px solid var(--lite-border);
        border-radius: 8px;
        font-size: 0.85rem;
        margin-top: 10px;
    }

    .status-dot {
        height: 8px;
        width: 8px;
        border-radius: 50%;
        background-color: #cbd5e1;
        display: inline-block;
        margin-right: 6px;
    }

    .status-dot.active {
        background-color: #10b981;
        box-shadow: 0 0 8px rgba(16, 185, 129, 0.4);
    }

    .status-dot.busy {
        background-color: #f59e0b;
        animation: pulse 1.5s infinite;
    }

    @keyframes pulse {
        0% {
            opacity: 1;
        }

        50% {
            opacity: 0.5;
        }

        100% {
            opacity: 1;
        }
    }

    /* Viewer Area */
    .viewer-area {
        flex: 1;
        position: relative;
        background: #000;
    }

    #openseadragon-viewer {
        width: 100%;
        height: 100%;
        background-color: #020617;
        /* Very dark slate */
    }

    /* Tech Overlays */
    .viewer-overlay-info {
        position: absolute;
        bottom: 20px;
        right: 20px;
        background: rgba(15, 23, 42, 0.85);
        backdrop-filter: blur(8px);
        padding: 10px 15px;
        border-radius: 6px;
        color: #94a3b8;
        font-size: 0.75rem;
        border: 1px solid rgba(255, 255, 255, 0.1);
        pointer-events: none;
    }

    .feature-tags {
        display: flex;
        flex-wrap: wrap;
        gap: 8px;
        margin-bottom: 24px;
    }

    .tag {
        font-size: 0.7rem;
        padding: 4px 10px;
        background: #eff6ff;
        color: #3b82f6;
        border-radius: 20px;
        font-weight: 600;
    }

    /* Spinner */
    .loading-overlay {
        position: absolute;
        inset: 0;
        background: rgba(15, 23, 42, 0.7);
        backdrop-filter: blur(4px);
        display: none;
        /* Flex when active */
        flex-direction: column;
        justify-content: center;
        align-items: center;
        z-index: 50;
        color: white;
    }

    .tech-spinner {
        width: 40px;
        height: 40px;
        border: 3px solid rgba(0, 188, 212, 0.3);
        border-top-color: var(--lite-primary);
        border-radius: 50%;
        animation: spin 1s linear infinite;
        margin-bottom: 16px;
    }

    @keyframes spin {
        100% {
            transform: rotate(360deg);
        }
    }

    /* Tablet Layout */
    @media (max-width: 992px) {
        .lite-wrapper {
            height: auto;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }

        .lite-main-row {
            flex-direction: column;
        }

        .lite-sidebar {
            width: 100%;
            height: auto;
            border-right: none;
            border-bottom: 1px solid var(--lite-border);
            order: 2; /* Sidebar below viewer on mobile */
        }

        .viewer-area {
            height: 50vh;
            min-height: 300px;
            order: 1; /* Viewer on top */
        }

        .sidebar-content {
            max-height: 40vh;
            overflow-y: auto;
        }
    }

    /* Mobile Layout */
    @media (max-width: 576px) {
        .lite-wrapper {
            height: 100vh;
            height: 100dvh; /* Dynamic viewport height for mobile browsers */
            min-height: unset;
        }

        .lite-sidebar {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            height: auto;
            max-height: 50vh;
            z-index: 100;
            border-radius: 20px 20px 0 0;
            box-shadow: 0 -4px 20px rgba(0, 0, 0, 0.15);
            transform: translateY(calc(100% - 60px));
            transition: transform 0.3s ease;
        }

        .lite-sidebar.expanded {
            transform: translateY(0);
        }

        .lite-sidebar::before {
            content: '';
            display: block;
            width: 40px;
            height: 4px;
            background: #cbd5e1;
            border-radius: 2px;
            margin: 12px auto 8px;
        }

        .sidebar-header {
            padding: 12px 20px;
            cursor: pointer;
        }

        .sidebar-content {
            padding: 16px 20px;
            max-height: calc(50vh - 100px);
        }

        .sidebar-footer {
            padding: 12px 20px;
            font-size: 0.65rem;
        }

        .viewer-area {
            height: calc(100vh - 60px);
            height: calc(100dvh - 60px);
        }

        .lite-brand {
            font-size: 1.2rem;
        }

        .control-group {
            margin-bottom: 20px;
        }

        .group-label {
            font-size: 0.65rem;
        }

        .drop-zone {
            padding: 20px 15px;
        }

        .drop-zone i {
            font-size: 1.5rem;
        }

        .drop-text {
            font-size: 0.8rem;
        }

        .btn-tech {
            padding: 12px;
            font-size: 0.85rem;
        }

        .feature-tags {
            margin-bottom: 16px;
        }

        .tag {
            font-size: 0.6rem;
            padding: 3px 8px;
        }

        #inference-log {
            height: 60px;
            font-size: 0.6rem;
        }

        .viewer-overlay-info {
            bottom: 70px;
            right: 10px;
            padding: 6px 10px;
            font-size: 0.65rem;
        }

        /* PWA standalone mode adjustments */
        body.pwa-standalone .lite-wrapper {
            height: 100vh;
            height: 100dvh;
        }
    }

    /* Touch-friendly enhancements */
    @media (pointer: coarse) {
        .drop-zone {
            min-height: 100px;
        }

        .btn-tech {
            min-height: 48px;
        }

        .status-row {
            min-height: 44px;
        }
    }

    /* Safe area insets for notched devices */
    @supports (padding: env(safe-area-inset-bottom)) {
        .lite-sidebar {
            padding-bottom: env(safe-area-inset-bottom);
        }
    }
</style>

<div class="lite-wrapper">
    <div class="lite-main-row">

        <!-- Sidebar -->
        <div class="lite-sidebar">
            <div class="sidebar-header">
                <div class="lite-brand">
                    <i class="fas fa-leaf text-success me-2" style="font-size: 0.8em; opacity:0.8;"></i>
                    LITE<strong>PATH</strong>
                </div>
                <div class="lite-tagline">Client-Side Foundation Model</div>
            </div>

            <div class="sidebar-content">
                <div class="feature-tags">
                    <span class="tag">WebGPU</span>
                    <span class="tag">Private</span>
                    <span class="tag">Zero-Install</span>
                </div>

                <!-- Input Section -->
                <div class="control-group">
                    <div class="group-label">
                        1. Data Source
                        <button id="btn-reset" class="btn-reset"
                            style="display:none; margin-left: auto; background: none; border: none; color: #ef4444; font-size: 0.7rem; cursor: pointer; text-transform: uppercase; font-weight: 700;">
                            <i class="fas fa-trash-alt"></i> Reset
                        </button>
                    </div>
                    <div class="drop-zone" id="drop-zone">
                        <i class="fas fa-microscope"></i>
                        <div class="drop-text" id="drop-text">Select Slide File</div>
                        <div class="drop-sub">Drag & Drop .svs, .tiff, .ndpi</div>
                        <input class="file-input-hidden" type="file" id="wsiSingleFile" accept=".svs,.tiff,.tif,.ndpi">
                    </div>
                    <div id="file-info" class="mt-2 text-center"
                        style="font-size: 0.75rem; color: var(--lite-primary);"></div>
                </div>

                <!-- Task Selection -->
                <div class="control-group">
                    <div class="group-label">2. Analysis Task</div>
                    <select id="task-selector" style="width: 100%; padding: 10px 12px; border: 1px solid #e2e8f0; border-radius: 6px; font-size: 13px; cursor: pointer; background: white;">
                        <!-- Options populated by JS -->
                    </select>
                    <div id="task-info" style="font-size: 11px; color: #64748b; margin-top: 8px;">
                        <!-- Task description populated by JS -->
                    </div>
                </div>

                <!-- Analysis Section -->
                <div class="control-group">
                    <div class="group-label">3. Run Analysis</div>
                    <button id="btn-run-inference" class="btn-tech" disabled>
                        <i class="fas fa-play"></i> RUN MODEL
                    </button>

                    <div class="status-row">
                        <span>Engine Status</span>
                        <span id="model-status-text"><span class="status-dot active"></span>Ready</span>
                    </div>
                </div>

                <!-- Debug / Log -->
                <div class="control-group">
                    <div class="group-label">System Log</div>
                    <div id="inference-log"
                        style="font-family: monospace; font-size: 0.7rem; color: #64748b; height: 100px; overflow-y: auto; background: #f8fafc; padding: 8px; border-radius: 4px; border: 1px solid #e2e8f0;">
                        > System initialized.<br>
                        > Waiting for input...
                    </div>
                </div>
            </div>

            <div class="sidebar-footer">
                HKUST SMART Lab © 2026
            </div>
        </div>

        <!-- Viewer -->
        <div class="viewer-area">
            <div id="openseadragon-viewer"></div>

            <div id="loading-overlay" class="loading-overlay">
                <div class="tech-spinner"></div>
                <div style="letter-spacing: 2px; font-size: 0.8rem; font-weight: 600;">PROCESSING</div>
            </div>

            <div class="viewer-overlay-info">
                <i class="fas fa-cube me-1"></i> WebGPU Enabled
            </div>
        </div>

    </div>
</div>

<!-- Dependencies -->
<!-- OpenSeadragon -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/openseadragon/4.1.0/openseadragon.min.js"></script>
<!-- GeoTIFF -->
<script src="https://cdn.jsdelivr.net/npm/geotiff"></script>
<!-- ONNX Runtime Web -->
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

<script>
    const _T = {
        'lung-nsclc': {
            id: 'lung-nsclc', n: 'Lung Cancer Subtyping', d: 'Classify NSCLC into LUAD vs LUSC',
            _c: 'subtyping', _s: 0x76c, _k: 0x64, _f: 1, l: ['LUAD', 'LUSC'],
            m: { a: 'MIL/Lung-NSCLC_APS.onnx', c: 'MIL/Lung-NSCLC.onnx' }
        },
        'gastric-grade': {
            id: 'gastric-grade', n: 'Gastric Cancer Grading', d: 'Classify gastric cancer grade (Low vs High)',
            _c: 'grading', _s: 0x76c, _k: 0x64, _f: 1, l: ['Low Grade', 'High Grade'],
            m: { a: 'MIL/Gastric-Grade_APS.onnx', c: 'MIL/Gastric-Grade.onnx' }
        }
    };

    const _M = { p: 'FM/LiteFM_pre.onnx', q: 'FM/LiteFM_post.onnx', i: 224, e: 384, t: 197, f: 1024, a: 768 };
    const _B = 'ckpts/';
    let _cT = 'lung-nsclc';

    let viewer, tiff, tiffImages = [], tiffPool;

    function initTaskSelector() {
        const select = document.getElementById('task-selector');
        if (!select) return;
        for (const tid in _T) {
            const t = _T[tid];
            const opt = document.createElement('option');
            opt.value = tid;
            opt.innerText = t.n;
            if (tid === _cT) opt.selected = true;
            select.appendChild(opt);
        }
        select.addEventListener('change', async (e) => {
            _cT = e.target.value;
            const t = _T[_cT];
            log(`Switched to: ${t.n}`);
            updateTaskInfo(t);
            await loadTaskModels(_cT);
        });
        updateTaskInfo(_T[_cT]);
    }

    function updateTaskInfo(t) {
        const infoDiv = document.getElementById('task-info');
        if (!infoDiv) return;
        infoDiv.innerHTML = `<div style="margin-bottom: 4px;">${t.d}</div><div><strong>Classes:</strong> ${t.l.join(' vs ')}</div>`;
    }

    window.addEventListener('load', initTaskSelector);


    function log(msg) {
        const logDiv = document.getElementById('inference-log');
        const line = document.createElement('div');
        line.innerText = `> ${msg}`;
        logDiv.appendChild(line);
        logDiv.scrollTop = logDiv.scrollHeight;
    }

    function logUpdatable(msg) {
        const logDiv = document.getElementById('inference-log');
        const line = document.createElement('div');
        line.innerText = `> ${msg}`;
        logDiv.appendChild(line);
        logDiv.scrollTop = logDiv.scrollHeight;
        return {
            update: (newMsg) => {
                line.innerText = `> ${newMsg}`;
                logDiv.scrollTop = logDiv.scrollHeight;
            }
        };
    }

    // Initialize OpenSeadragon
    function initViewer() {
        if (viewer) viewer.destroy();

        viewer = OpenSeadragon({
            id: "openseadragon-viewer",
            prefixUrl: "https://cdnjs.cloudflare.com/ajax/libs/openseadragon/4.1.0/images/",
            showNavigator: true,
            animationTime: 0.4,
            maxZoomPixelRatio: 2,
            minZoomLevel: 0.1,
            visibilityRatio: 0.1,
            zoomPerScroll: 1.5,
            crossOriginPolicy: "Anonymous",
            constrainDuringPan: true,
            placeholderFillStyle: "#020617"
        });
    }

    // File Handling
    const dropZone = document.getElementById('drop-zone');
    const fileInput = document.getElementById('wsiSingleFile');
    const resetBtn = document.getElementById('btn-reset');

    dropZone.addEventListener('dragover', (e) => {
        e.preventDefault();
        dropZone.classList.add('dragover');
    });

    dropZone.addEventListener('dragleave', () => {
        dropZone.classList.remove('dragover');
    });

    dropZone.addEventListener('drop', (e) => {
        e.preventDefault();
        dropZone.classList.remove('dragover');
        if (e.dataTransfer.files.length) {
            fileInput.files = e.dataTransfer.files;
            handleFile(e.dataTransfer.files[0]);
        }
    });

    fileInput.addEventListener('change', (e) => {
        if (e.target.files.length) handleFile(e.target.files[0]);
    });

    resetBtn.addEventListener('click', () => {
        // Reset State
        if (viewer) viewer.forceRedraw(); // Clear?
        initViewer(); // Re-init to clear canvas

        tiffImages = [];
        window.litePathTiffImages = [];

        // Reset UI
        document.getElementById('drop-text').innerText = "Select Slide File";
        document.getElementById('file-info').innerHTML = "";
        dropZone.style.display = "block";
        resetBtn.style.display = "none";
        document.getElementById('btn-run-inference').disabled = true;

        // Reset Input
        fileInput.value = "";

        log("System reset.");
    });

    async function handleFile(file) {
        if (!file) return;

        // Reset
        tiffImages = [];

        document.getElementById('drop-text').innerText = file.name;
        document.getElementById('file-info').innerHTML = `<i class="fas fa-spinner fa-spin"></i> Analyzing pyramid...`;

        // Show Reset
        resetBtn.style.display = "inline-block";

        log(`Reading file: ${file.name} (${(file.size / 1024 / 1024).toFixed(1)}MB)`);

        try {
            // Create pool with more workers for parallel decode (default is 4, increase to 8)
            if (!tiffPool) tiffPool = new GeoTIFF.Pool(8);
            tiff = await GeoTIFF.fromBlob(file);

            const count = await tiff.getImageCount();

            const allImages = [];
            for (let i = 0; i < count; i++) {
                const img = await tiff.getImage(i);
                allImages.push({
                    index: i,
                    image: img,
                    width: img.getWidth(),
                    height: img.getHeight()
                });
            }

            allImages.sort((a, b) => b.width - a.width);
            const mainImage = allImages[0];
            const mainAspectRatio = mainImage.width / mainImage.height;

            const aspectTolerance = 0.1;
            for (const img of allImages) {
                const aspectRatio = img.width / img.height;
                const aspectDiff = Math.abs(aspectRatio - mainAspectRatio) / mainAspectRatio;

                if (aspectDiff <= aspectTolerance) {
                    tiffImages.push(img);
                }
            }

            tiffImages.sort((a, b) => b.width - a.width);

            window.litePathTiffImages = tiffImages;

            const mainImg = tiffImages[0];
            const levelsInfo = tiffImages.map(d => `${d.width}x${d.height}`).join(', ');
            log(`Pyramid Levels: [${levelsInfo}]`);

            document.getElementById('file-info').innerHTML =
                `<i class="fas fa-check-circle"></i> Loaded (${mainImg.width}x${mainImg.height})`;

            const maxLevel = Math.ceil(Math.log2(Math.max(mainImg.width, mainImg.height)));

            const tileSource = {
                width: mainImg.width,
                height: mainImg.height,
                tileSize: 256,
                tileOverlap: 0,
                minLevel: 0,
                maxLevel: maxLevel,

                getTileUrl: function (level, x, y) {
                    return `litepath://tile/${level}/${x}/${y}`;
                },

                getTilePostData: function(level, x, y) {
                    return { level, x, y };
                },

                downloadTileStart: function(imageJob) {
                    const tiffImages = window.litePathTiffImages;
                    if (!tiffImages || tiffImages.length === 0) {
                        imageJob.finish(null, null, "TIFF images not loaded");
                        return;
                    }

                    const { level, x, y } = imageJob.postData;
                    const nativeImg = tiffImages[0];
                    const sourceMaxLevel = maxLevel;
                    const tileSize = 256;

                    (async () => {
                        try {
                            const scale = Math.pow(2, sourceMaxLevel - level);

                            const nativeTileSize = tileSize * scale;
                            const srcX = x * nativeTileSize;
                            const srcY = y * nativeTileSize;
                            const srcW = Math.min(nativeTileSize, nativeImg.width - srcX);
                            const srcH = Math.min(nativeTileSize, nativeImg.height - srcY);

                            if (srcW <= 0 || srcH <= 0 || srcX >= nativeImg.width || srcY >= nativeImg.height) {
                                imageJob.finish(null, null, "Tile out of bounds");
                                return;
                            }

                            const outW = Math.ceil(srcW / scale);
                            const outH = Math.ceil(srcH / scale);

                            let bestImg = tiffImages[0];
                            for (let i = 0; i < tiffImages.length; i++) {
                                const pyramidScale = nativeImg.width / tiffImages[i].width;
                                const regionWidthInPyramid = srcW / pyramidScale;
                                if (regionWidthInPyramid >= outW * 0.5) {
                                    bestImg = tiffImages[i];
                                } else {
                                    break;
                                }
                            }

                            const pyramidScale = nativeImg.width / bestImg.width;
                            const pX = Math.floor(srcX / pyramidScale);
                            const pY = Math.floor(srcY / pyramidScale);
                            const pW = Math.max(1, Math.ceil(srcW / pyramidScale));
                            const pH = Math.max(1, Math.ceil(srcH / pyramidScale));

                            const clampedX = Math.max(0, Math.min(pX, bestImg.width - 1));
                            const clampedY = Math.max(0, Math.min(pY, bestImg.height - 1));
                            const clampedW = Math.max(1, Math.min(pW, bestImg.width - clampedX));
                            const clampedH = Math.max(1, Math.min(pH, bestImg.height - clampedY));

                            const rasters = await bestImg.image.readRasters({
                                window: [clampedX, clampedY, clampedX + clampedW, clampedY + clampedH],
                                width: outW,
                                height: outH,
                                pool: tiffPool,
                                interleave: false
                            });

                            const canvas = document.createElement('canvas');
                            canvas.width = outW;
                            canvas.height = outH;
                            const ctx = canvas.getContext('2d');
                            const imgData = ctx.createImageData(outW, outH);
                            const data = imgData.data;

                            let r = rasters[0];
                            let g = rasters[1];
                            let b = rasters[2];

                            if (!g || !b) {
                                g = r; b = r;
                            }

                            for (let i = 0; i < r.length; i++) {
                                data[i * 4] = r[i];
                                data[i * 4 + 1] = g[i];
                                data[i * 4 + 2] = b[i];
                                data[i * 4 + 3] = 255;
                            }

                            ctx.putImageData(imgData, 0, 0);

                            canvas.toBlob((blob) => {
                                const url = URL.createObjectURL(blob);
                                const img = new Image();
                                img.onload = () => {
                                    imageJob.finish(img);
                                    URL.revokeObjectURL(url);
                                };
                                img.onerror = (e) => {
                                    imageJob.finish(null, null, "Failed to create image from canvas");
                                };
                                img.src = url;
                            });

                        } catch (e) {
                            console.error("Tile loading error:", e);
                            imageJob.finish(null, null, e.message);
                        }
                    })();
                },

                downloadTileAbort: function(imageJob) {
                    // Nothing to abort for memory-based loading
                }
            };

            viewer.open(tileSource);

            document.getElementById('btn-run-inference').disabled = false;

        } catch (err) {
            console.error(err);
            log(`Error: ${err.message}`);
            document.getElementById('file-info').innerHTML = `<span style="color:ef4444"><i class="fas fa-times"></i> Error</span>`;
        }
    }

    // ============================================================================
    // Model Sessions
    // ============================================================================
    let liteFMPreSession = null;
    let liteFMPostSession = null;
    let milSession = null;
    let apsSession = null;
    const INFERENCE_BATCH_SIZE = 128;

    /**
     * Load feature extraction models (LiteFM_pre, LiteFM_post)
     * These are shared across all tasks
     */
    async function loadFeatureModels() {
        if (liteFMPreSession && liteFMPostSession) return;

        log("Loading LiteFM feature models (WebGPU)...");
        try {
            // Check for WebGPU adapter capabilities
            let gpuAdapter = null;
            let supportsF16 = false;
            if (navigator.gpu) {
                gpuAdapter = await navigator.gpu.requestAdapter();
                if (gpuAdapter) {
                    supportsF16 = gpuAdapter.features.has('shader-f16');
                    log(`WebGPU adapter: ${gpuAdapter.name || 'default'}, FP16: ${supportsF16}`);
                }
            }

            const gpuOptions = {
                executionProviders: ['webgpu', 'wasm'],
                graphOptimizationLevel: 'all',
                // Free Dimension Override - fix batch size for better optimization
                freeDimensionOverrides: {
                    batch: INFERENCE_BATCH_SIZE
                },
                // IO Binding - keep output on GPU to reduce CPU-GPU transfers
                preferredOutputLocation: 'gpu-buffer'
            };

            const prePath = _B + _M.p;
            liteFMPreSession = await ort.InferenceSession.create(prePath, gpuOptions);
            log("LiteFM_pre loaded.");

            const postPath = _B + _M.q;
            liteFMPostSession = await ort.InferenceSession.create(postPath, gpuOptions);
            log("LiteFM_post loaded.");

            await loadTaskModels(_cT);

        } catch (e) {
            console.error(e);
            log(`Feature model load failed: ${e.message}`);
            // Fallback: try without IO Binding
            log("Retrying without IO Binding...");
            try {
                const fallbackOptions = {
                    executionProviders: ['webgpu', 'wasm'],
                    graphOptimizationLevel: 'all'
                };
                const prePath = _B + _M.p;
                liteFMPreSession = await ort.InferenceSession.create(prePath, fallbackOptions);
                log("LiteFM_pre loaded (fallback mode).");

                const postPath = _B + _M.q;
                liteFMPostSession = await ort.InferenceSession.create(postPath, fallbackOptions);
                log("LiteFM_post loaded (fallback mode).");

                await loadTaskModels(_cT);
            } catch (e2) {
                console.error(e2);
                log(`Fallback load also failed: ${e2.message}`);
            }
        }
    }

    async function loadTaskModels(tid) {
        const t = _T[tid];
        if (!t) { log(`Unknown task: ${tid}`); return; }

        log(`Loading models for ${t.n}...`);

        try {
            const wasmOpts = { executionProviders: ['wasm'] };

            if (milSession) { await milSession.release(); milSession = null; }
            if (apsSession) { await apsSession.release(); apsSession = null; }

            if (t._f && t.m.a) {
                apsSession = await ort.InferenceSession.create(_B + t.m.a, wasmOpts);
                log(`APS loaded for ${t.n}.`);
            }

            milSession = await ort.InferenceSession.create(_B + t.m.c, wasmOpts);
            log(`MIL loaded for ${t.n}.`);

            document.getElementById('model-status-text').innerHTML =
                `<span class="status-dot active"></span>${t.n} Ready`;

        } catch (e) {
            console.error(e);
            log(`Task model load failed: ${e.message}`);
            document.getElementById('model-status-text').innerHTML =
                `<span class="status-dot"></span>Load Failed`;
        }
    }

    // Load models on init
    loadFeatureModels();

    // ============================================================================
    // WSI Processing Functions
    // ============================================================================

    /**
     * Convert RGB to HSV
     * Returns H: 0-180, S: 0-255, V: 0-255 (OpenCV convention)
     */
    function rgbToHsv(r, g, b) {
        r /= 255; g /= 255; b /= 255;
        const max = Math.max(r, g, b);
        const min = Math.min(r, g, b);
        const d = max - min;

        let h = 0;
        const s = max === 0 ? 0 : d / max;
        const v = max;

        if (d !== 0) {
            switch (max) {
                case r: h = ((g - b) / d + (g < b ? 6 : 0)) / 6; break;
                case g: h = ((b - r) / d + 2) / 6; break;
                case b: h = ((r - g) / d + 4) / 6; break;
            }
        }
        return [h * 180, s * 255, v * 255];
    }

    /**
     * Tissue segmentation using HSV color space
     * Returns binary mask (Uint8Array) where 1 = tissue, 0 = background
     */
    function segmentTissue(imageData) {
        const { width, height, data } = imageData;
        const mask = new Uint8Array(width * height);

        // HSV thresholds for tissue detection
        const satMin = 15, satMax = 255;
        const valMin = 25, valMax = 220;

        for (let i = 0; i < width * height; i++) {
            const r = data[i * 4];
            const g = data[i * 4 + 1];
            const b = data[i * 4 + 2];
            const [, s, v] = rgbToHsv(r, g, b);
            mask[i] = (s >= satMin && s <= satMax && v >= valMin && v <= valMax) ? 1 : 0;
        }

        return { mask, width, height };
    }

    /**
     * Extract patch coordinates from tissue mask
     * Returns array of {x, y} coordinates in native image space
     */
    function extractPatchCoords(mask, maskWidth, maskHeight, nativeWidth, nativeHeight, patchSize = 512, tissueThreshold = 0.3) {
        const scaleX = nativeWidth / maskWidth;
        const scaleY = nativeHeight / maskHeight;
        const coords = [];

        // Grid-based extraction
        for (let y = 0; y < nativeHeight - patchSize; y += patchSize) {
            for (let x = 0; x < nativeWidth - patchSize; x += patchSize) {
                // Map to mask coordinates
                const maskX = Math.floor(x / scaleX);
                const maskY = Math.floor(y / scaleY);
                const maskPatchW = Math.ceil(patchSize / scaleX);
                const maskPatchH = Math.ceil(patchSize / scaleY);

                // Count tissue pixels
                let tissueCount = 0, totalCount = 0;
                for (let my = maskY; my < Math.min(maskY + maskPatchH, maskHeight); my++) {
                    for (let mx = maskX; mx < Math.min(maskX + maskPatchW, maskWidth); mx++) {
                        if (mask[my * maskWidth + mx] === 1) tissueCount++;
                        totalCount++;
                    }
                }

                if (totalCount > 0 && tissueCount / totalCount >= tissueThreshold) {
                    coords.push({ x, y });
                }
            }
        }
        return coords;
    }

    /**
     * Uniform sampling of indices
     */
    function uniformSample(total, count) {
        if (total <= count) return Array.from({ length: total }, (_, i) => i);
        const step = total / count;
        return Array.from({ length: count }, (_, i) => Math.floor(i * step));
    }

    /**
     * Read a single patch from TIFF at native coordinates
     * Returns ImageData (patchSize x patchSize)
     */
    async function readPatch(x, y, patchSize, targetSize) {
        const nativeImg = tiffImages[0];
        if (!nativeImg) throw new Error("TIFF not loaded");

        // Find best pyramid level
        let bestImg = nativeImg;
        const scale = patchSize / targetSize;  // e.g., 512/224 ≈ 2.3

        for (let i = 0; i < tiffImages.length; i++) {
            const pyramidScale = nativeImg.width / tiffImages[i].width;
            if (pyramidScale <= scale * 1.5) {
                bestImg = tiffImages[i];
            } else {
                break;
            }
        }

        // Map coordinates to pyramid level
        const pyramidScale = nativeImg.width / bestImg.width;
        const pX = Math.floor(x / pyramidScale);
        const pY = Math.floor(y / pyramidScale);
        const pW = Math.ceil(patchSize / pyramidScale);
        const pH = Math.ceil(patchSize / pyramidScale);

        // Clamp to bounds
        const clampedX = Math.max(0, Math.min(pX, bestImg.width - 1));
        const clampedY = Math.max(0, Math.min(pY, bestImg.height - 1));
        const clampedW = Math.max(1, Math.min(pW, bestImg.width - clampedX));
        const clampedH = Math.max(1, Math.min(pH, bestImg.height - clampedY));

        // Read from TIFF and resize to targetSize
        const rasters = await bestImg.image.readRasters({
            window: [clampedX, clampedY, clampedX + clampedW, clampedY + clampedH],
            width: targetSize,
            height: targetSize,
            pool: tiffPool,
            interleave: false
        });

        // Convert to ImageData
        const imgData = new ImageData(targetSize, targetSize);
        const pixels = imgData.data;
        let r = rasters[0], g = rasters[1] || r, b = rasters[2] || r;

        for (let i = 0; i < r.length; i++) {
            pixels[i * 4] = r[i];
            pixels[i * 4 + 1] = g[i];
            pixels[i * 4 + 2] = b[i];
            pixels[i * 4 + 3] = 255;
        }

        return imgData;
    }

    /**
     * Get thumbnail from TIFF (smallest pyramid level)
     */
    async function getThumbnail(maxSize = 1024) {
        if (!tiffImages || tiffImages.length === 0) throw new Error("TIFF not loaded");

        // Find smallest level that's still >= maxSize, or just the smallest
        let bestImg = tiffImages[tiffImages.length - 1];
        for (let i = tiffImages.length - 1; i >= 0; i--) {
            if (tiffImages[i].width >= maxSize || tiffImages[i].height >= maxSize) {
                bestImg = tiffImages[i];
                break;
            }
        }

        // Calculate output size maintaining aspect ratio
        const scale = Math.min(maxSize / bestImg.width, maxSize / bestImg.height);
        const outW = Math.floor(bestImg.width * scale);
        const outH = Math.floor(bestImg.height * scale);

        const rasters = await bestImg.image.readRasters({
            width: outW,
            height: outH,
            pool: tiffPool,
            interleave: false
        });

        const imgData = new ImageData(outW, outH);
        const pixels = imgData.data;
        let r = rasters[0], g = rasters[1] || r, b = rasters[2] || r;

        for (let i = 0; i < r.length; i++) {
            pixels[i * 4] = r[i];
            pixels[i * 4 + 1] = g[i];
            pixels[i * 4 + 2] = b[i];
            pixels[i * 4 + 3] = 255;
        }

        return imgData;
    }

    // ============================================================================
    // Inference Logic
    // ============================================================================

    /**
     * Preprocess image data for model input
     * Converts RGBA ImageData to CHW Float32Array with ImageNet normalization
     */
    function preprocessImage(imgData, targetSize) {
        const { data } = imgData;
        const tensorData = new Float32Array(1 * 3 * targetSize * targetSize);
        const mean = [0.485, 0.456, 0.406];
        const std = [0.229, 0.224, 0.225];

        let rPtr = 0;
        let gPtr = targetSize * targetSize;
        let bPtr = 2 * targetSize * targetSize;

        for (let i = 0; i < targetSize * targetSize; i++) {
            const r = data[i * 4] / 255.0;
            const g = data[i * 4 + 1] / 255.0;
            const b = data[i * 4 + 2] / 255.0;

            tensorData[rPtr++] = (r - mean[0]) / std[0];
            tensorData[gPtr++] = (g - mean[1]) / std[1];
            tensorData[bPtr++] = (b - mean[2]) / std[2];
        }

        return tensorData;
    }

    /**
     * Preprocess a batch of patches for model input
     * Returns Float32Array [batchSize, 3, 224, 224]
     */
    function preprocessBatch(patches, targetSize) {
        const batchSize = patches.length;
        const output = new Float32Array(batchSize * 3 * targetSize * targetSize);
        const mean = [0.485, 0.456, 0.406];
        const std = [0.229, 0.224, 0.225];

        for (let b = 0; b < batchSize; b++) {
            const data = patches[b].data;
            const offset = b * 3 * targetSize * targetSize;

            for (let i = 0; i < targetSize * targetSize; i++) {
                const r = data[i * 4] / 255.0;
                const g = data[i * 4 + 1] / 255.0;
                const b_val = data[i * 4 + 2] / 255.0;

                output[offset + i] = (r - mean[0]) / std[0];
                output[offset + targetSize * targetSize + i] = (g - mean[1]) / std[1];
                output[offset + 2 * targetSize * targetSize + i] = (b_val - mean[2]) / std[2];
            }
        }

        return output;
    }

    function computeAPSInput(embeddings, numPatches) {
        const ed = _M.e, nt = _M.t;
        const apsInput = new Float32Array(numPatches * ed * 2);

        for (let i = 0; i < numPatches; i++) {
            const offset = i * nt * ed;
            for (let j = 0; j < ed; j++) {
                apsInput[i * ed * 2 + j] = embeddings[offset + j];
            }
            const pt = nt - 1;
            for (let j = 0; j < ed; j++) {
                let sum = 0;
                for (let k = 1; k < nt; k++) { sum += embeddings[offset + k * ed + j]; }
                apsInput[i * ed * 2 + ed + j] = sum / pt;
            }
        }

        return apsInput;
    }

    /**
     * Get top K indices from scores
     */
    function getTopKIndices(scores, k) {
        const indexed = Array.from(scores).map((score, idx) => ({ score, idx }));
        indexed.sort((a, b) => b.score - a.score);
        return indexed.slice(0, k).map(item => item.idx);
    }

    /**
     * Softmax function
     */
    function softmax(logits) {
        const maxLogit = Math.max(...Array.from(logits));
        const expLogits = Array.from(logits).map(l => Math.exp(l - maxLogit));
        const sumExp = expLogits.reduce((a, b) => a + b, 0);
        return expLogits.map(e => e / sumExp);
    }

    /**
     * Update progress display in loading overlay
     */
    function updateProgress(stage, current, total, detail = '') {
        const progressText = document.querySelector('#loading-overlay span');
        if (progressText) {
            const pct = total > 0 ? Math.round(current / total * 100) : 0;
            progressText.textContent = `${stage}: ${pct}% ${detail}`;
        }
    }

    document.getElementById('btn-run-inference').addEventListener('click', async function () {
        const overlay = document.getElementById('loading-overlay');
        overlay.style.display = "flex";

        const t = _T[_cT];
        const startTime = performance.now();
        const inputSize = _M.i, numTokens = _M.t, embeddingDim = _M.e, featureDim = _M.f, apsInputDim = _M.a;

        try {
            if (!liteFMPreSession || !liteFMPostSession) await loadFeatureModels();
            if (!liteFMPreSession || !liteFMPostSession) throw new Error("Feature models not ready");
            if (!milSession) await loadTaskModels(_cT);
            if (!milSession) throw new Error("Task models not ready");

            log(`Starting ${t.n} analysis...`);

            // Check if TIFF is loaded
            if (!tiffImages || tiffImages.length === 0) {
                throw new Error("No WSI loaded. Please load a TIFF file first.");
            }

            const nativeWidth = tiffImages[0].width;
            const nativeHeight = tiffImages[0].height;
            log(`WSI size: ${nativeWidth} x ${nativeHeight}`);

            // ================================================================
            // Step 1: Tissue Segmentation
            // ================================================================
            updateProgress('Segmentation', 0, 100);
            log("Step 1: Tissue segmentation...");

            const thumbnail = await getThumbnail(1024);
            const { mask, width: maskW, height: maskH } = segmentTissue(thumbnail);
            const tissuePixels = mask.reduce((a, b) => a + b, 0);
            const tissueRatio = (tissuePixels / mask.length * 100).toFixed(1);
            log(`Segmentation: ${maskW}x${maskH}, tissue=${tissueRatio}%`);

            // ================================================================
            // Step 2: Extract Patch Coordinates
            // ================================================================
            updateProgress('Extracting patches', 0, 100);
            log("Step 2: Extracting patch coordinates...");

            const patchSize = 512;
            const allCoords = extractPatchCoords(mask, maskW, maskH, nativeWidth, nativeHeight, patchSize, 0.3);

            if (allCoords.length === 0) {
                throw new Error("No tissue patches found. Check the image.");
            }

            const sampleIndices = uniformSample(allCoords.length, t._s);
            const sampledCoords = sampleIndices.map(i => allCoords[i]);

            // ================================================================
            // Step 3: Feature Extraction + APS Selection
            // Optimizations: Multi-batch prefetch, Batch APS inference, Pipeline
            // ================================================================
            const step3Log = logUpdatable("Step 3: Feature extraction... 0%");

            const batchSize = INFERENCE_BATCH_SIZE;
            const embSize = numTokens * embeddingDim;  // 197 * 384
            const bufferThreshold = 2500;  // Trigger selection when buffer reaches this size
            const k_a = t._k;  // Top-K to keep (e.g., 100)
            const PREFETCH_QUEUE_SIZE = 3;  // Number of batches to prefetch ahead

            // Helper: read a batch of patches
            async function readBatchPatches(coords) {
                return await Promise.all(
                    coords.map(coord => readPatch(coord.x, coord.y, patchSize, inputSize))
                );
            }

            // Helper: run batch inference with LiteFM_pre
            async function runBatchInference(patches) {
                if (patches.length === 0) return [];
                const actualBatchSize = patches.length;

                let paddedPatches = patches;
                if (actualBatchSize < INFERENCE_BATCH_SIZE) {
                    paddedPatches = [...patches];
                    const lastPatch = patches[patches.length - 1];
                    while (paddedPatches.length < INFERENCE_BATCH_SIZE) {
                        paddedPatches.push(lastPatch);
                    }
                }

                const batchData = preprocessBatch(paddedPatches, inputSize);
                const inputTensor = new ort.Tensor('float32', batchData, [INFERENCE_BATCH_SIZE, 3, inputSize, inputSize]);
                const results = await liteFMPreSession.run({ input: inputTensor });

                const outputTensor = results.embedding;
                let outputData;
                if (outputTensor.location === 'gpu-buffer') {
                    outputData = await outputTensor.getData();
                    outputTensor.dispose();
                } else {
                    outputData = outputTensor.data;
                }

                const embeddings = [];
                for (let i = 0; i < actualBatchSize; i++) {
                    const emb = new Float32Array(embSize);
                    for (let j = 0; j < embSize; j++) {
                        emb[j] = outputData[i * embSize + j];
                    }
                    embeddings.push(emb);
                }
                return embeddings;
            }

            // Helper: compute APS scores for embeddings sequentially
            // Note: ONNX session doesn't support concurrent run() calls
            async function computeAPSScoresBatch(embeddings) {
                const scores = [];
                for (const emb of embeddings) {
                    const apsIn = new Float32Array(apsInputDim);
                    for (let j = 0; j < embeddingDim; j++) { apsIn[j] = emb[j]; }
                    const npt = numTokens - 1;
                    for (let j = 0; j < embeddingDim; j++) {
                        let sum = 0;
                        for (let k = 1; k < numTokens; k++) { sum += emb[k * embeddingDim + j]; }
                        apsIn[embeddingDim + j] = sum / npt;
                    }
                    const apsInputTensor = new ort.Tensor('float32', apsIn, [1, apsInputDim]);
                    const apsResults = await apsSession.run({ features: apsInputTensor });
                    scores.push(apsResults.scores.data[0]);
                }
                return scores;
            }

            let selectedEmbeddings;

            if (t._f && apsSession && k_a > 0) {
                // Streaming Top-K with buffer + multi-batch prefetch
                const embBuffer = [];    // Array of embeddings
                const scoreBuffer = [];  // Corresponding scores
                let firstFlag = true;

                const totalBatches = Math.ceil(sampledCoords.length / batchSize);

                // Initialize prefetch queue with first N batches
                const prefetchQueue = [];
                for (let i = 0; i < Math.min(PREFETCH_QUEUE_SIZE, totalBatches); i++) {
                    const startIdx = i * batchSize;
                    const endIdx = Math.min(startIdx + batchSize, sampledCoords.length);
                    prefetchQueue.push(readBatchPatches(sampledCoords.slice(startIdx, endIdx)));
                }

                for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
                    const pct = Math.round(batchIdx / totalBatches * 100);
                    step3Log.update(`Step 3: Feature extraction... ${pct}%`);
                    updateProgress('Feature extraction', pct, 100);

                    // Get patches from prefetch queue
                    const patches = await prefetchQueue.shift();

                    // Refill prefetch queue
                    const nextPrefetchIdx = batchIdx + PREFETCH_QUEUE_SIZE;
                    if (nextPrefetchIdx < totalBatches) {
                        const startIdx = nextPrefetchIdx * batchSize;
                        const endIdx = Math.min(startIdx + batchSize, sampledCoords.length);
                        prefetchQueue.push(readBatchPatches(sampledCoords.slice(startIdx, endIdx)));
                    }

                    // Run LiteFM_pre
                    const batchEmbeddings = await runBatchInference(patches);

                    // Add to buffer (scores will be computed when buffer is full)
                    for (const emb of batchEmbeddings) {
                        embBuffer.push(emb);
                        scoreBuffer.push(-Infinity);  // Placeholder
                    }

                    // Check if buffer threshold reached
                    if (embBuffer.length >= bufferThreshold) {
                        const startIdx = firstFlag ? 0 : k_a;
                        firstFlag = false;

                        // Batch compute APS scores for new entries only
                        const newEmbeddings = embBuffer.slice(startIdx);
                        const newScores = await computeAPSScoresBatch(newEmbeddings);
                        for (let idx = 0; idx < newScores.length; idx++) {
                            scoreBuffer[startIdx + idx] = newScores[idx];
                        }

                        // Get top-K indices
                        const indexed = scoreBuffer.map((score, idx) => ({ score, idx }));
                        indexed.sort((a, b) => b.score - a.score);
                        const topKIndices = indexed.slice(0, k_a).map(item => item.idx);

                        // Keep only top-K in buffer
                        const newEmbBuffer = topKIndices.map(idx => embBuffer[idx]);
                        const newScoreBuffer = topKIndices.map(idx => scoreBuffer[idx]);
                        embBuffer.length = 0;
                        scoreBuffer.length = 0;
                        embBuffer.push(...newEmbBuffer);
                        scoreBuffer.push(...newScoreBuffer);
                    }
                }

                // Final selection if buffer still has more than k_a
                if (embBuffer.length > k_a) {
                    // Batch score remaining unscored entries
                    const unscoredIndices = [];
                    const unscoredEmbs = [];
                    for (let idx = 0; idx < embBuffer.length; idx++) {
                        if (scoreBuffer[idx] === -Infinity) {
                            unscoredIndices.push(idx);
                            unscoredEmbs.push(embBuffer[idx]);
                        }
                    }
                    if (unscoredEmbs.length > 0) {
                        const newScores = await computeAPSScoresBatch(unscoredEmbs);
                        for (let i = 0; i < unscoredIndices.length; i++) {
                            scoreBuffer[unscoredIndices[i]] = newScores[i];
                        }
                    }

                    const indexed = scoreBuffer.map((score, idx) => ({ score, idx }));
                    indexed.sort((a, b) => b.score - a.score);
                    const topKIndices = indexed.slice(0, k_a).map(item => item.idx);
                    selectedEmbeddings = topKIndices.map(idx => embBuffer[idx]);
                } else {
                    selectedEmbeddings = embBuffer;
                }

                step3Log.update("Step 3: Feature extraction... Done");
            } else {
                // No APS: extract all embeddings with multi-batch prefetch
                const allEmbeddings = [];
                const totalBatches = Math.ceil(sampledCoords.length / batchSize);

                // Initialize prefetch queue
                const prefetchQueue = [];
                for (let i = 0; i < Math.min(PREFETCH_QUEUE_SIZE, totalBatches); i++) {
                    const startIdx = i * batchSize;
                    const endIdx = Math.min(startIdx + batchSize, sampledCoords.length);
                    prefetchQueue.push(readBatchPatches(sampledCoords.slice(startIdx, endIdx)));
                }

                for (let batchIdx = 0; batchIdx < totalBatches; batchIdx++) {
                    const pct = Math.round(batchIdx / totalBatches * 100);
                    step3Log.update(`Step 3: Feature extraction... ${pct}%`);
                    updateProgress('Feature extraction', pct, 100);

                    const patches = await prefetchQueue.shift();

                    // Refill prefetch queue
                    const nextPrefetchIdx = batchIdx + PREFETCH_QUEUE_SIZE;
                    if (nextPrefetchIdx < totalBatches) {
                        const startIdx = nextPrefetchIdx * batchSize;
                        const endIdx = Math.min(startIdx + batchSize, sampledCoords.length);
                        prefetchQueue.push(readBatchPatches(sampledCoords.slice(startIdx, endIdx)));
                    }

                    const batchEmbeddings = await runBatchInference(patches);
                    allEmbeddings.push(...batchEmbeddings);
                }
                step3Log.update("Step 3: Feature extraction... Done");
                selectedEmbeddings = allEmbeddings;
            }

            // ================================================================
            // Step 4: LiteFM_post (compute final features)
            // Optimized with batch inference
            // ================================================================
            const step5Log = logUpdatable("Step 4: Computing features... 0%");

            const allFeatures = [];  // [K, 1024]
            const postBatchSize = INFERENCE_BATCH_SIZE;  // Use global constant for Graph Capture compatibility
            const totalPostBatches = Math.ceil(selectedEmbeddings.length / postBatchSize);

            for (let batchIdx = 0; batchIdx < totalPostBatches; batchIdx++) {
                const i = batchIdx * postBatchSize;
                const batchEnd = Math.min(i + postBatchSize, selectedEmbeddings.length);
                const batchEmbeddings = selectedEmbeddings.slice(i, batchEnd);
                const actualBatchSize = batchEmbeddings.length;

                // Pad to fixed batch size if needed
                let paddedEmbeddings = batchEmbeddings;
                if (actualBatchSize < INFERENCE_BATCH_SIZE) {
                    paddedEmbeddings = [...batchEmbeddings];
                    const lastEmb = batchEmbeddings[batchEmbeddings.length - 1];
                    while (paddedEmbeddings.length < INFERENCE_BATCH_SIZE) {
                        paddedEmbeddings.push(lastEmb);
                    }
                }

                // Concatenate embeddings into batch tensor [INFERENCE_BATCH_SIZE, 197, 384]
                const embSize = numTokens * embeddingDim;
                const batchData = new Float32Array(INFERENCE_BATCH_SIZE * embSize);
                for (let b = 0; b < INFERENCE_BATCH_SIZE; b++) {
                    batchData.set(paddedEmbeddings[b], b * embSize);
                }

                const embTensor = new ort.Tensor('float32', batchData, [INFERENCE_BATCH_SIZE, numTokens, embeddingDim]);
                const postResults = await liteFMPostSession.run({ embedding: embTensor });

                // IO Binding: output may be GPU tensor, need to use getData()
                const outputTensor = postResults.features;
                let outputData;
                if (outputTensor.location === 'gpu-buffer') {
                    outputData = await outputTensor.getData();
                    outputTensor.dispose();
                } else {
                    outputData = outputTensor.data;
                }

                // Split batch output into individual features (only take actualBatchSize)
                for (let b = 0; b < actualBatchSize; b++) {
                    const feat = new Float32Array(featureDim);
                    for (let j = 0; j < featureDim; j++) {
                        feat[j] = outputData[b * featureDim + j];
                    }
                    allFeatures.push(feat);
                }

                const pct = Math.round(batchEnd / selectedEmbeddings.length * 100);
                step5Log.update(`Step 4: Computing features... ${pct}%`);
                updateProgress('Computing features', pct, 100);
            }
            step5Log.update("Step 4: Computing features... Done");

            // ================================================================
            // Step 5: MIL Classification
            // ================================================================
            log("Step 5: Classification...");

            // Concatenate all features into [K, 1024]
            const K = allFeatures.length;
            const featuresConcat = new Float32Array(K * featureDim);
            for (let i = 0; i < K; i++) {
                featuresConcat.set(allFeatures[i], i * featureDim);
            }

            const milInput = new ort.Tensor('float32', featuresConcat, [K, featureDim]);
            const milResults = await milSession.run({ features: milInput });
            const logits = milResults.logits.data;

            const probabilities = softmax(logits);
            const prediction = probabilities[1] > probabilities[0] ? 1 : 0;
            const predLabel = t.l[prediction];
            const confidence = Math.max(...probabilities) * 100;

            const totalTime = performance.now() - startTime;
            log(`=== ${predLabel} (${confidence.toFixed(1)}%) ===`);
            log(`Time: ${(totalTime / 1000).toFixed(1)}s`);

            overlay.style.display = "none";

            const prevOverlay = document.getElementById('result-overlay');
            if (prevOverlay) prevOverlay.remove();

            const resultDiv = document.createElement('div');
            resultDiv.id = 'result-overlay';
            resultDiv.style.cssText = 'position:absolute;left:50%;top:50%;transform:translate(-50%,-50%);padding:20px 30px;background:rgba(15,23,42,0.95);backdrop-filter:blur(8px);border-radius:12px;border:1px solid var(--lite-primary);box-shadow:0 0 30px rgba(0,188,212,0.3);pointer-events:none;text-align:center;color:white;z-index:100';

            resultDiv.innerHTML = `
                <div style="font-size: 11px; text-transform: uppercase; letter-spacing: 1px; color: #94a3b8; margin-bottom: 8px;">${t.n}</div>
                <div style="font-size: 28px; font-weight: 700; color: var(--lite-primary); margin-bottom: 4px;">${predLabel}</div>
                <div style="font-size: 16px; color: #e2e8f0;">Confidence: ${confidence.toFixed(1)}%</div>
                <div style="font-size: 12px; color: #64748b; margin-top: 8px;">
                    <div>${t.l[0]}: ${(probabilities[0] * 100).toFixed(1)}%</div>
                    <div>${t.l[1]}: ${(probabilities[1] * 100).toFixed(1)}%</div>
                </div>
                <div style="font-size: 10px; color: #475569; margin-top: 12px; border-top: 1px solid #334155; padding-top: 8px;">Time: ${(totalTime / 1000).toFixed(1)}s</div>
            `;

            viewer.canvas.appendChild(resultDiv);

            // Auto-hide after 10 seconds (longer for full analysis)
            setTimeout(() => {
                if (resultDiv.parentNode) {
                    resultDiv.style.transition = 'opacity 0.5s';
                    resultDiv.style.opacity = '0';
                    setTimeout(() => resultDiv.remove(), 500);
                }
            }, 10000);

        } catch (e) {
            console.error(e);
            log(`Inference error: ${e.message}`);
            overlay.style.display = "none";
        }
    });

    // Mobile sidebar toggle
    function initMobileSidebar() {
        const sidebar = document.querySelector('.lite-sidebar');
        const header = document.querySelector('.sidebar-header');

        if (!sidebar || !header) return;

        // Check if mobile
        const isMobile = () => window.innerWidth <= 576;

        // Toggle sidebar on header click (mobile only)
        header.addEventListener('click', (e) => {
            if (isMobile()) {
                sidebar.classList.toggle('expanded');
            }
        });

        // Close sidebar when clicking on viewer (mobile only)
        document.querySelector('.viewer-area')?.addEventListener('click', () => {
            if (isMobile() && sidebar.classList.contains('expanded')) {
                sidebar.classList.remove('expanded');
            }
        });

        // Swipe gesture support
        let touchStartY = 0;
        let touchEndY = 0;

        sidebar.addEventListener('touchstart', (e) => {
            touchStartY = e.changedTouches[0].screenY;
        }, { passive: true });

        sidebar.addEventListener('touchend', (e) => {
            touchEndY = e.changedTouches[0].screenY;
            handleSwipe();
        }, { passive: true });

        function handleSwipe() {
            if (!isMobile()) return;

            const swipeDistance = touchStartY - touchEndY;
            const threshold = 50;

            if (swipeDistance > threshold) {
                // Swipe up - expand
                sidebar.classList.add('expanded');
            } else if (swipeDistance < -threshold) {
                // Swipe down - collapse
                sidebar.classList.remove('expanded');
            }
        }
    }

    // Detect standalone PWA mode
    function checkPWAMode() {
        const isStandalone = window.matchMedia('(display-mode: standalone)').matches
            || window.navigator.standalone
            || document.referrer.includes('android-app://');

        if (isStandalone) {
            document.body.classList.add('pwa-standalone');
        }
    }

    initViewer();
    initMobileSidebar();
    checkPWAMode();

    // Service Worker Registration
    if ('serviceWorker' in navigator) {
        navigator.serviceWorker.register('/showcase/LitePath/sw.js')
            .then((registration) => {
                console.log('[PWA] Service Worker registered:', registration.scope);
            })
            .catch((error) => {
                console.log('[PWA] Service Worker registration failed:', error);
            });
    }
</script>
</body>
</html>